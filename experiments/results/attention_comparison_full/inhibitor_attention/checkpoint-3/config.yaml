dataset:
  cache_dir: data/cache
  name: imdb
  num_test_samples: 100
  num_train_samples: 100
  test_file: data/test.csv
  train_file: data/train.csv
evaluation:
  batch_size: 32
  metrics:
  - accuracy
  - latency
  - memory_usage
experiment:
  attention_types:
  - inhibitor
  - quadratic_inhibitor
  - approx_exp
  description: Comparison of standard, inhibitor, quadratic inhibitor, consmax, approx_exp,
    standard with ReLU activation, and quadratic inhibitor with ReLU activation
  name: attention_comparison_full
  use_quadratic_inhibitor_relu: true
  use_relu_activation: false
logging:
  eval_steps: 200
  log_dir: experiments/results/attention_comparison_full
  save_steps: 1000
  save_total_limit: 2
model:
  attention_probs_dropout_prob: 0.1
  hidden_dropout_prob: 0.1
  hidden_size: 384
  intermediate_size: 1536
  max_position_embeddings: 512
  num_attention_heads: 6
  num_hidden_layers: 3
  type: bert
  type_vocab_size: 2
  vocab_size: 30522
training:
  batch_size: 16
  fp16: false
  gradient_accumulation_steps: 1
  learning_rate: 2.0e-05
  max_seq_length: 128
  num_train_epochs: 3
  warmup_steps: 500
  weight_decay: 0.01
